# ğŸ§  Notebooks: Intelligent Complaint Analysis for Financial Services

This directory documents the notebook-based workflow behind the Intelligent Complaint Analysis project. These notebooks detail the full pipeline: from cleaning raw complaints data to building a retrieval-augmented generation (RAG) system powered by chunking, embedding, indexing, prompting, and response evaluation.

---

## ğŸ““ Available Notebooks

### 1. `EDA_and_Data_Preprocessing.ipynb`

ğŸ” **Purpose:**  
Explore and clean raw complaint data from the CFPB to prepare it for semantic indexing.

ğŸ§© **Key Steps:**
- Load original data and inspect basic structure
- Analyze product-level complaint distributions
- Visualize word count distributions
- Filter narratives based on word count and key product proxies
- Normalize complaint text (e.g., punctuation, dates, unicode)
- Export cleaned dataset in `.csv` and `.parquet` formats

ğŸ“Š **Key Insight:**  
Filtered dataset contains substantive complaints across five major financial products, cleaned and normalized for downstream language modeling.

---

### 2. `text-chunking_embedding_vector-store_indexing.ipynb`

ğŸ§  **Purpose:**  
Transform cleaned complaints into a vector-searchable format using chunking, embeddings, and FAISS indexing.

âš™ï¸ **Key Steps:**
- Initialize `ComplaintVectorPipeline`
- Perform recursive chunking using LangChain's `RecursiveCharacterTextSplitter`
- Embed chunks via `sentence-transformers` using the `all-MiniLM-L6-v2` model
- Normalize vectors and build a FAISS index (`IndexFlatIP`)
- Attach metadata (product, issue, ID) to each chunk
- Save artifacts: chunked DataFrame and FAISS index

ğŸ“¦ **Output:**  
Vector database ready for semantic querying of financial complaint excerpts.

---

### 3. `rag-core-logic-and-evaluation.ipynb`

ğŸ§ª **Purpose:**  
Execute and validate the full RAG loop â€” retrieval, prompt assembly, model response, and answer analysis.

ğŸ” **Key Steps:**
- Load cleaned data and vector index
- Configure the `RAGAgent`, composed of:
  - `ComplaintVectorPipeline.search()` for semantic chunk retrieval
  - `PromptBuilder` to inject context into structured instruction prompt
  - `LLMClient` or `LLMClient_For_Llama` to generate responses using Mistral
- Evaluate system on 9 representative user queries
- Record results in structured summary table for analysis

ğŸ“ˆ **Key Outcome:**  
System generates coherent, bullet-pointed answers to financial queries based on complaint corpus context â€” validated through comparison and qualitative scoring.

---

## ğŸ§‘â€ğŸ’» Usage Notes

- Launch notebooks using Jupyter Lab or VS Code
- Ensure all required modules (in `requirements.txt`) are installed
- Generated visualizations and text outputs are inline and reproducible
- Notebook outputs feed directly into the `src/` modules and the Streamlit app

---

## ğŸ“Œ Notes

- Quantized Mistral model used via `llama_cpp` for offline generation
- Evaluation demonstrates prompt engineering and model alignment with task goals
- Output summaries follow structured financial QA guidance

---

Feel free to extend the pipeline with new product categories, evaluation prompts, or model variants. These notebooks form the analytical backbone of the Intelligent Complaint Analysis system.