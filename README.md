# ğŸ’¡ Intelligent Complaint Analysis for Financial Services

A modular Retrieval-Augmented Generation (RAG) system for analyzing consumer complaints from the Consumer Financial Protection Bureau (CFPB). This project transforms textual complaint data into a vector-searchable format, enabling semantic exploration, evaluation, and structured generation. Built with low-resource environments in mind, it supports both notebook-based workflows and a Streamlit UI powered by a quantized Mistral model via `llama_cpp`.

---

## ğŸ“ Project Structure
ğŸ“ project_root/
â”œâ”€â”€ ğŸ“ notebooks/                            # Jupyter notebooks for development & evaluation
â”‚   â”œâ”€â”€ EDA_and_Data_Preprocessing.ipynb          # EDA, normalization, word filtering
â”‚   â”œâ”€â”€ text-chunking_embedding_vector-indexing.ipynb  # Chunking, embeddings, FAISS indexing
â”‚   â””â”€â”€ rag-core-logic-and-evaluation.ipynb       # Retrieval, prompting, generation & analysis
â”‚
â”œâ”€â”€ ğŸ“ src/                                  # Source code for RAG pipeline and app
â”‚   â”œâ”€â”€ ğŸ“ core/                                   # Core logic: preprocessing, embedding, retrieval
â”‚   â”‚   â”œâ”€â”€ ComplaintVectorPipeline.py                # Chunker, embedder, retriever, index builder
â”‚   â”‚   â””â”€â”€ utils.py                                  # Text normalization, loaders, plots
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ models/                                 # Model orchestration & RAG abstraction
â”‚   â”‚   â””â”€â”€ RAG_Pipeline.py                           # PromptBuilder, LLMClient, RAGAgent classes
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ services/
â”‚       â””â”€â”€ ğŸ“ streamlit/                            # Streamlit app frontend
â”‚           â””â”€â”€ rag_interface.py                        # Interface using quantized Mistral model
â”‚
â”œâ”€â”€ ğŸ“ data/                                 # Data storage
â”‚   â”œâ”€â”€ ğŸ“ raw/                                    # Original CFPB complaint CSVs
â”‚   â””â”€â”€ ğŸ“ processed/                              # Filtered & chunked data for retrieval
â”‚
â”œâ”€â”€ ğŸ“ vector_store/                        # FAISS vector index
â”‚   â””â”€â”€ complaints_index.faiss                  # Prebuilt FAISS index
â”‚
â”œâ”€â”€ ğŸ“ models/                             # LLMs and embeddings
â”‚   â””â”€â”€ ğŸ“ mistral_condensed/                    # Quantized Mistral model (.gguf format)
â”‚
â”œâ”€â”€ ğŸ“ tests/                              # Unit and integration tests
â”‚   â”œâ”€â”€ test_ComplaintVectorPipeline.py         # Chunking, embeddings, retrieval tests
â”‚   â”œâ”€â”€ test_RAGAgent.py                        # Prompting and generation logic
â”‚   â”œâ”€â”€ test_utils.py                           # Normalizer and utility function tests
â”‚   â””â”€â”€ test_rag_interface_minimal.py           # Minimal app test (without full model load)
â”‚
â””â”€â”€ requirements.txt                      # Python dependencies for the project


---

## ğŸš€ Core Components

### âœ… Data Processing (`ComplaintVectorPipeline.py`)
- Recursive chunking (`langchain.text_splitter`)
- Embedding with `sentence-transformers`
- FAISS inner-product index for similarity search
- Metadata mapping for traceability

### ğŸ¨ Prompting & Generation (`RAG_Pipeline.py`)
- `PromptBuilder`: Inserts context and user query into structured template
- `LLMClient`: Interfaces with Hugging Face pipelines
- `LLMClient_For_Llama`: Custom wrapper for quantized Mistral (`llama_cpp`)
- `RAGAgent`: Glues together search â†’ prompt â†’ generate

### ğŸ“Š Evaluation (`rag-core-logic-and-evaluation.ipynb`)
- Simulated RAG pipeline run over 9 curated financial questions
- Answers analyzed via tabular summaries
- Tests Mistral's contextual accuracy and prompt shaping

---

## ğŸŒ Streamlit Interface (`rag_interface.py`)

A streamlined interactive app using:

-  Quantized Mistral (7B) via `llama_cpp` for low-resource CPU inference
-  Cached embeddings and FAISS index
-  Real-time question input and answer rendering
-  Stateless prompt wrapping with `LLMClient_For_Llama`

### Setup

```bash
# for notebook implementaion create a .venv file with python 3.13.
python -m venv .venv
source .venv/Scripts/activate   # On bash: .\llama_venv\Scripts\Activate
# Create virtual environment with Python 3.10(for streamlit app)
python3.10 -m venv llama_venv
source llama_venv/Scripts/activate  # On bash: .\llama_venv\Scripts\Activate

# Install dependencies
pip install -r requirements.txt

# Launch the app
streamlit run src/services/streamlit/rag_interface.py
